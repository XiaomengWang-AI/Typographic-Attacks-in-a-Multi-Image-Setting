# Typographic-Attacks-in-a-Multi-Image-Setting
This repository contains the source code and experimental data for the paper "Typographic Attacks in a Multi-Image Setting" presented at NAACL 2025. 
This paper propose a realistic multi-image setting and effective attack strategies in this setting.
This paper explores the vulnerabilities of Large Vision-Language Models (LVLMs), such as CLIP and InstructBLIP, to typographic attacks where texts are superimposed on images to cause misclassifications.

## Dependencies
For the complete list of dependencies, please refer to the `requirements.txt` file included in the repository.

## Acknowledgement
- Thanks to the authors of [open_clip]（https://github.com/mlfoundations/open_clip) for their open-source code, which inspired and informed our development process.
- Thanks to the authors of [Self-Gen-Typo-Attack]（https://github.com/mqraitem/Self-Gen-Typo-Attack) for their open-source code, which inspired and informed our development process.
- Additional thanks to NAACL 2025 reviewers for their valuable feedback.


